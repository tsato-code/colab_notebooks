{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hashibiro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO3HPiLfk3TI000vzk7L/kb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsato-code/colab_notebooks/blob/main/hashibiro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHuu8_imiiJr",
        "outputId": "13756719-c50a-4aab-c4f9-3c29d3ed2b74"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Apr 13 14:25:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAbBtNfSim_3",
        "outputId": "f484d018-4af8-4562-8311-3584abf0bdb3"
      },
      "source": [
        "# 関連リポジトリをクローン\n",
        "%cd /content\n",
        "!git clone https://github.com/KaiyangZhou/vsumm-reinforce"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'vsumm-reinforce'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121\u001b[K\n",
            "Receiving objects: 100% (121/121), 641.05 KiB | 16.87 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7hWFe4ojDuQ",
        "outputId": "26b3d11b-4d07-4d69-d91a-e360e62b6916"
      },
      "source": [
        "# データセットと学習済みモデルをダウンロード\n",
        "%cd vsumm-reinforce\n",
        "#!wget http://www.eecs.qmul.ac.uk/~kz303/vsumm-reinforce/datasets.tar.gz\n",
        "#!tar -xvzf datasets.tar.gz\n",
        "#!wget http://www.eecs.qmul.ac.uk/~kz303/vsumm-reinforce/models.tar.gz\n",
        "#!tar -xvzf models.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vsumm-reinforce\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BZmwIQIjIrx",
        "outputId": "c5ad614e-fe17-4fbe-dc02-97609f964603"
      },
      "source": [
        "%cd ..\n",
        "# GoogLeNet for Image Classification\n",
        "!git clone https://github.com/conan7882/GoogLeNet-Inception-tf\n",
        "%cd GoogLeNet-Inception-tf\n",
        "!wget https://www.dropbox.com/sh/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy\n",
        "%cd ..\n",
        "# Kernel Temporal Segmentation\n",
        "!wget http://pascal.inrialpes.fr/data2/potapov/med_summaries/kts_ver1.1.tar.gz\n",
        "!tar -zxvf kts_ver1.1.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'GoogLeNet-Inception-tf'...\n",
            "remote: Enumerating objects: 332, done.\u001b[K\n",
            "remote: Total 332 (delta 0), reused 0 (delta 0), pack-reused 332\u001b[K\n",
            "Receiving objects: 100% (332/332), 11.78 MiB | 20.55 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "/content/GoogLeNet-Inception-tf\n",
            "--2021-04-13 14:25:34--  https://www.dropbox.com/sh/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy [following]\n",
            "--2021-04-13 14:25:35--  https://www.dropbox.com/sh/raw/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com/cd/0/inline/BMhxCz_Vkr7bvLKVjaZcFizjwujRHucE0glr2pta2YyWhc1g-0qtygOnX-TfFoeAa-jSCtA2Fyd9pT0lWdq9sldCEl-5PzHYlR_iBNpe1weeQSMNzJLYzkqoj92MBDiKpKxlnsw1N2DyuQWyciLxlTpJ/file# [following]\n",
            "--2021-04-13 14:25:35--  https://uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com/cd/0/inline/BMhxCz_Vkr7bvLKVjaZcFizjwujRHucE0glr2pta2YyWhc1g-0qtygOnX-TfFoeAa-jSCtA2Fyd9pT0lWdq9sldCEl-5PzHYlR_iBNpe1weeQSMNzJLYzkqoj92MBDiKpKxlnsw1N2DyuQWyciLxlTpJ/file\n",
            "Resolving uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com (uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com (uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BMi6bRC7M2aNn5ZcnoG-XZeXunKNPofCnmqVEXlUjnUkGkTPPddII8kqFHLhrS4yOIKeAgfXFmQh6TvcyNKUm0jlspAMRg3aoivlB87U7UXgZsgToy6QUIRYNYxgcH1vU74GWfp7_l09rfWKhHW4XJEIhqfb7b8MXnG4RcK2MVq9lcdJppHwa4-R9IK4FkcKXMC23gev5VRbe1M4vDKgwS9XDJrZifrcHlGZZ8DX37gj6XzCs0jzkBj2QgqlP2I_45Q1zxVFa7zsMyGevhTCQjsnnFNQjnG-EvZxtaO-ZOf_IOnaQ0RoDMm9ptQk2UNzMM4FL9ArGTQvuVMxolo0eKMqxjJ8iSJRXg8zKBYNlpnXh7bj8TdagO0IL2FIx8wnTzM/file [following]\n",
            "--2021-04-13 14:25:36--  https://uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com/cd/0/inline2/BMi6bRC7M2aNn5ZcnoG-XZeXunKNPofCnmqVEXlUjnUkGkTPPddII8kqFHLhrS4yOIKeAgfXFmQh6TvcyNKUm0jlspAMRg3aoivlB87U7UXgZsgToy6QUIRYNYxgcH1vU74GWfp7_l09rfWKhHW4XJEIhqfb7b8MXnG4RcK2MVq9lcdJppHwa4-R9IK4FkcKXMC23gev5VRbe1M4vDKgwS9XDJrZifrcHlGZZ8DX37gj6XzCs0jzkBj2QgqlP2I_45Q1zxVFa7zsMyGevhTCQjsnnFNQjnG-EvZxtaO-ZOf_IOnaQ0RoDMm9ptQk2UNzMM4FL9ArGTQvuVMxolo0eKMqxjJ8iSJRXg8zKBYNlpnXh7bj8TdagO0IL2FIx8wnTzM/file\n",
            "Reusing existing connection to uc97dc01e822b85572caf0a3a90c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28000395 (27M) [application/octet-stream]\n",
            "Saving to: ‘googlenet.npy’\n",
            "\n",
            "googlenet.npy       100%[===================>]  26.70M  91.4MB/s    in 0.3s    \n",
            "\n",
            "2021-04-13 14:25:37 (91.4 MB/s) - ‘googlenet.npy’ saved [28000395/28000395]\n",
            "\n",
            "/content\n",
            "--2021-04-13 14:25:37--  http://pascal.inrialpes.fr/data2/potapov/med_summaries/kts_ver1.1.tar.gz\n",
            "Resolving pascal.inrialpes.fr (pascal.inrialpes.fr)... 194.199.16.17\n",
            "Connecting to pascal.inrialpes.fr (pascal.inrialpes.fr)|194.199.16.17|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3431 (3.4K) [application/x-gzip]\n",
            "Saving to: ‘kts_ver1.1.tar.gz’\n",
            "\n",
            "kts_ver1.1.tar.gz   100%[===================>]   3.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-13 14:25:37 (622 MB/s) - ‘kts_ver1.1.tar.gz’ saved [3431/3431]\n",
            "\n",
            "kts_ver1.1/\n",
            "kts_ver1.1/cpd_auto.py\n",
            "kts_ver1.1/cpd_nonlin.py\n",
            "kts_ver1.1/demo.py\n",
            "kts_ver1.1/README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2hHlZ72lLGH",
        "outputId": "f63ff317-1007-44a9-95e3-83c30ecc770f"
      },
      "source": [
        "!mkdir -p data/original\n",
        "%cd data/original"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/original\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1MknzUdBlpE6",
        "outputId": "15d5df58-1217-453b-f35c-1c525ed94c8b"
      },
      "source": [
        "!pip install pytube\n",
        "from pytube import YouTube\n",
        "\n",
        "data_dir = '/content/data/original/'\n",
        "# hot pepper beauty\n",
        "YouTube(\"https://www.youtube.com/watch?v=rwt3oS_mFVQ\").streams.first().download(data_dir+'test01')\n",
        "# GREEN DAKARA\n",
        "YouTube(\"https://www.youtube.com/watch?v=cShbQ2pQs94\").streams.first().download(data_dir+'test02')\n",
        "# ポカリスウェット\n",
        "YouTube(\"https://www.youtube.com/watch?v=cKM2HQLK8Pg\").streams.first().download(data_dir+'test03')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.7/dist-packages (10.7.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/data/original/test03/ポカリスエットCM｜「でも君が見えた」篇 30秒 B.mp4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tyxn0zcluRP"
      },
      "source": [
        "# mp4ファイルを移動\n",
        "!mv /content/data/original/*/*.mp4 /content/data/original"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCySbbTv-6Hb"
      },
      "source": [
        "# スクリプトを修正\n",
        "text = r'''\n",
        "#!/bin/bash\n",
        "\n",
        "\"\"\"\n",
        "This script decompose a video into frames\n",
        "How to use: replace path_to_videos and path_to_frames with real paths\n",
        "\"\"\"\n",
        "\n",
        "for f in /content/data/original/*.mp4\n",
        "do\n",
        "  echo \"Processing $f file...\"\n",
        "  # take action on each file. $f store current file name\\\n",
        "  basename=$(ff=${f%.ext} ; echo ${ff##*/})\n",
        "  name=$(echo $basename | cut -d'.' --complement -f2-)\n",
        "  echo $f\n",
        " mkdir -p /content/data/frames/\"$name\"\n",
        " ffmpeg -i \"$f\" -f image2 -qscale:v 2 /content/data/frames/\"$name\"/%06d.jpg\n",
        "done\n",
        "'''\n",
        "with open('/content/vsumm-reinforce/extra-tools/videos2frames.sh', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noCCp8eEnjv5",
        "outputId": "625b83ac-bea8-42cc-8889-588e1caeedd7"
      },
      "source": [
        "# 修正したスクリプトを実行\n",
        "%cd /content/vsumm-reinforce/extra-tools\n",
        "!./videos2frames.sh"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vsumm-reinforce/extra-tools\n",
            "./videos2frames.sh: line 6: $'\\nThis script decompose a video into frames\\nHow to use: replace path_to_videos and path_to_frames with real paths\\n': command not found\n",
            "Processing /content/data/original/ポカリスエットCM｜「でも君が見えた」篇 30秒 B.mp4 file...\n",
            "/content/data/original/ポカリスエットCM｜「でも君が見えた」篇 30秒 B.mp4\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/data/original/ポカリスエットCM｜「でも君が見えた」篇 30秒 B.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "  Duration: 00:00:30.09, start: 0.000000, bitrate: 656 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 558 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/06/2021.\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/06/2021.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x55795531a000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/data/frames/ポカリスエットCM｜「でも君が見えた」篇 30秒 B/%06d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/06/2021.\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  900 fps=630 q=2.0 Lsize=N/A time=00:00:30.03 bitrate=N/A speed=  21x    \n",
            "video:21332kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Processing /content/data/original/GREEN DA・KA・RA やさしい麦茶　　またあえるボトル『ムギちゃんとふしぎなおじさん』篇 short version 35秒 なぎさちゃん 佐藤二朗 サントリー.mp4 file...\n",
            "/content/data/original/GREEN DA・KA・RA やさしい麦茶　　またあえるボトル『ムギちゃんとふしぎなおじさん』篇 short version 35秒 なぎさちゃん 佐藤二朗 サントリー.mp4\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/data/original/GREEN DA・KA・RA やさしい麦茶　　またあえるボトル『ムギちゃんとふしぎなおじさん』篇 short version 35秒 なぎさちゃん 佐藤二朗 サントリー.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:00:35.39, start: 0.000000, bitrate: 524 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 426 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x55cd4b9ca000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/data/frames/GREEN DA・KA・RA やさしい麦茶　　またあえるボトル『ムギちゃんとふしぎなおじさん』篇 short version 35秒 なぎさちゃん 佐藤二朗 サントリー/%06d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn, 23.98 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  847 fps=634 q=2.0 Lsize=N/A time=00:00:35.32 bitrate=N/A speed=26.5x    \n",
            "video:25646kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Processing /content/data/original/【ホットペッパービューティー】～ナダルとオカンの押し問答　美容室篇　～.mp4 file...\n",
            "/content/data/original/【ホットペッパービューティー】～ナダルとオカンの押し問答　美容室篇　～.mp4\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/data/original/【ホットペッパービューティー】～ナダルとオカンの押し問答　美容室篇　～.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "  Duration: 00:00:30.09, start: 0.000000, bitrate: 405 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 306 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/18/2021.\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/18/2021.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x563f325d8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/data/frames/【ホットペッパービューティー】～ナダルとオカンの押し問答　美容室篇　～/%06d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn, 23.98 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/18/2021.\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  720 fps=626 q=2.0 Lsize=N/A time=00:00:30.03 bitrate=N/A speed=26.1x    \n",
            "video:20923kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbSxQroNo6b2",
        "outputId": "44954f4a-dd10-4c38-e8f7-703226db7614"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 60kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.32.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (54.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUz4l8sT_grg"
      },
      "source": [
        "# 特徴量抽出のコード\n",
        "text = r'''\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# File: inception_pretrained.py\n",
        "# Author: Qian Ge <geqian1001@gmail.com>\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "sys.path.append('../')\n",
        "import loader as loader\n",
        "from src.nets.googlenet import GoogLeNet\n",
        "import h5py\n",
        "import src.models.layers as L\n",
        "\n",
        "# PRETRINED_PATH = '/home/qge2/workspace/data/pretrain/inception/googlenet.npy'\n",
        "# DATA_PATH = '../data/'\n",
        "PRETRINED_PATH = '/content/GoogLeNet-Inception-tf/googlenet.npy'\n",
        "DATA_PATH = '/content/data/frames/test01'\n",
        "DATASET_PATH = '/content/vsumm-reinforce/datasets/eccv16_dataset_pokari_google_pool5.h5'\n",
        "IM_CHANNEL = 3\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--pretrained_path', type=str, default=PRETRINED_PATH,\n",
        "                        help='Directory of pretrain model')\n",
        "    parser.add_argument('--im_name', type=str, default='.jpg',\n",
        "                        help='Part of image name')\n",
        "    parser.add_argument('--data_path', type=str, default=DATA_PATH,\n",
        "                        help='Directory of test images')\n",
        "    \n",
        "    return parser.parse_args()\n",
        "\n",
        "def test_pre_trained():\n",
        "    FLAGS = get_args()\n",
        "    # Read ImageNet label into a dictionary\n",
        "    label_dict = loader.load_label_dict()\n",
        "    # Create a Dataflow object for test images\n",
        "    image_data = loader.read_image(\n",
        "        im_name=FLAGS.im_name, n_channel=IM_CHANNEL,\n",
        "        data_dir=FLAGS.data_path, batch_size=1)\n",
        "\n",
        "    # Create a testing GoogLeNet model\n",
        "    test_model = GoogLeNet(\n",
        "        n_channel=IM_CHANNEL, n_class=1000, pre_trained_path=FLAGS.pretrained_path)\n",
        "    test_model.create_test_model()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        dataset = h5py.File(DATASET_PATH, 'w')\n",
        "        video_name = FLAGS.data_path.split('/')[-2]\n",
        "        features = np.empty((1, 1024), dtype=np.float64)  # Put dummy\n",
        "\n",
        "        while image_data.epochs_completed < 1:\n",
        "            # read batch files\n",
        "            batch_data = image_data.next_batch_dict()\n",
        "            # get batch file names\n",
        "            batch_file_name = image_data.get_batch_file_name()[0]\n",
        "            # get prediction results\n",
        "            #pred = sess.run(test_model.layers['top_5'],\n",
        "            feature = sess.run(L.global_avg_pool(test_model.layers['inception_out']),\n",
        "                            feed_dict={test_model.image: batch_data['image']})\n",
        "            features = np.concatenate((features, feature))\n",
        "\n",
        "        dataset.create_dataset('{}/features_origin'.format(video_name), data=features[1:])\n",
        "        dataset.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_pre_trained()\n",
        "'''\n",
        "with open('/content/GoogLeNet-Inception-tf/examples/feature_extraction.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2gygOL2sNyO",
        "outputId": "2c2a7360-bf8c-41ef-ac8f-23fd0cd61686"
      },
      "source": [
        "%cd /content/GoogLeNet-Inception-tf/examples\n",
        "\n",
        "# これは一時的に必要なディレクトリ\n",
        "!mkdir -p /content/vsumm-reinforce/datasets\n",
        "# ディレクトリのパス設定次第でok\n",
        "!python feature_extraction.py"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GoogLeNet-Inception-tf/examples\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Load conv1_7x7_s2 weights!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Load conv1_7x7_s2 biases!\n",
            "Load conv2_3x3_reduce weights!\n",
            "Load conv2_3x3_reduce biases!\n",
            "Load conv2_3x3 weights!\n",
            "Load conv2_3x3 biases!\n",
            "Load inception_3a_1x1 weights!\n",
            "Load inception_3a_1x1 biases!\n",
            "Load inception_3a_3x3_reduce weights!\n",
            "Load inception_3a_3x3_reduce biases!\n",
            "Load inception_3a_3x3 weights!\n",
            "Load inception_3a_3x3 biases!\n",
            "Load inception_3a_5x5_reduce weights!\n",
            "Load inception_3a_5x5_reduce biases!\n",
            "Load inception_3a_5x5 weights!\n",
            "Load inception_3a_5x5 biases!\n",
            "Load inception_3a_pool_proj weights!\n",
            "Load inception_3a_pool_proj biases!\n",
            "Load inception_3b_1x1 weights!\n",
            "Load inception_3b_1x1 biases!\n",
            "Load inception_3b_3x3_reduce weights!\n",
            "Load inception_3b_3x3_reduce biases!\n",
            "Load inception_3b_3x3 weights!\n",
            "Load inception_3b_3x3 biases!\n",
            "Load inception_3b_5x5_reduce weights!\n",
            "Load inception_3b_5x5_reduce biases!\n",
            "Load inception_3b_5x5 weights!\n",
            "Load inception_3b_5x5 biases!\n",
            "Load inception_3b_pool_proj weights!\n",
            "Load inception_3b_pool_proj biases!\n",
            "Load inception_4a_1x1 weights!\n",
            "Load inception_4a_1x1 biases!\n",
            "Load inception_4a_3x3_reduce weights!\n",
            "Load inception_4a_3x3_reduce biases!\n",
            "Load inception_4a_3x3 weights!\n",
            "Load inception_4a_3x3 biases!\n",
            "Load inception_4a_5x5_reduce weights!\n",
            "Load inception_4a_5x5_reduce biases!\n",
            "Load inception_4a_5x5 weights!\n",
            "Load inception_4a_5x5 biases!\n",
            "Load inception_4a_pool_proj weights!\n",
            "Load inception_4a_pool_proj biases!\n",
            "Load inception_4b_1x1 weights!\n",
            "Load inception_4b_1x1 biases!\n",
            "Load inception_4b_3x3_reduce weights!\n",
            "Load inception_4b_3x3_reduce biases!\n",
            "Load inception_4b_3x3 weights!\n",
            "Load inception_4b_3x3 biases!\n",
            "Load inception_4b_5x5_reduce weights!\n",
            "Load inception_4b_5x5_reduce biases!\n",
            "Load inception_4b_5x5 weights!\n",
            "Load inception_4b_5x5 biases!\n",
            "Load inception_4b_pool_proj weights!\n",
            "Load inception_4b_pool_proj biases!\n",
            "Load inception_4c_1x1 weights!\n",
            "Load inception_4c_1x1 biases!\n",
            "Load inception_4c_3x3_reduce weights!\n",
            "Load inception_4c_3x3_reduce biases!\n",
            "Load inception_4c_3x3 weights!\n",
            "Load inception_4c_3x3 biases!\n",
            "Load inception_4c_5x5_reduce weights!\n",
            "Load inception_4c_5x5_reduce biases!\n",
            "Load inception_4c_5x5 weights!\n",
            "Load inception_4c_5x5 biases!\n",
            "Load inception_4c_pool_proj weights!\n",
            "Load inception_4c_pool_proj biases!\n",
            "Load inception_4d_1x1 weights!\n",
            "Load inception_4d_1x1 biases!\n",
            "Load inception_4d_3x3_reduce weights!\n",
            "Load inception_4d_3x3_reduce biases!\n",
            "Load inception_4d_3x3 weights!\n",
            "Load inception_4d_3x3 biases!\n",
            "Load inception_4d_5x5_reduce weights!\n",
            "Load inception_4d_5x5_reduce biases!\n",
            "Load inception_4d_5x5 weights!\n",
            "Load inception_4d_5x5 biases!\n",
            "Load inception_4d_pool_proj weights!\n",
            "Load inception_4d_pool_proj biases!\n",
            "Load inception_4e_1x1 weights!\n",
            "Load inception_4e_1x1 biases!\n",
            "Load inception_4e_3x3_reduce weights!\n",
            "Load inception_4e_3x3_reduce biases!\n",
            "Load inception_4e_3x3 weights!\n",
            "Load inception_4e_3x3 biases!\n",
            "Load inception_4e_5x5_reduce weights!\n",
            "Load inception_4e_5x5_reduce biases!\n",
            "Load inception_4e_5x5 weights!\n",
            "Load inception_4e_5x5 biases!\n",
            "Load inception_4e_pool_proj weights!\n",
            "Load inception_4e_pool_proj biases!\n",
            "Load inception_5a_1x1 weights!\n",
            "Load inception_5a_1x1 biases!\n",
            "Load inception_5a_3x3_reduce weights!\n",
            "Load inception_5a_3x3_reduce biases!\n",
            "Load inception_5a_3x3 weights!\n",
            "Load inception_5a_3x3 biases!\n",
            "Load inception_5a_5x5_reduce weights!\n",
            "Load inception_5a_5x5_reduce biases!\n",
            "Load inception_5a_5x5 weights!\n",
            "Load inception_5a_5x5 biases!\n",
            "Load inception_5a_pool_proj weights!\n",
            "Load inception_5a_pool_proj biases!\n",
            "Load inception_5b_1x1 weights!\n",
            "Load inception_5b_1x1 biases!\n",
            "Load inception_5b_3x3_reduce weights!\n",
            "Load inception_5b_3x3_reduce biases!\n",
            "Load inception_5b_3x3 weights!\n",
            "Load inception_5b_3x3 biases!\n",
            "Load inception_5b_5x5_reduce weights!\n",
            "Load inception_5b_5x5_reduce biases!\n",
            "Load inception_5b_5x5 weights!\n",
            "Load inception_5b_5x5 biases!\n",
            "Load inception_5b_pool_proj weights!\n",
            "Load inception_5b_pool_proj biases!\n",
            "Load loss3_classifier weights!\n",
            "Load loss3_classifier biases!\n",
            "2021-04-13 15:56:06.458402: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-13 15:56:06.461856: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-04-13 15:56:06.462216: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x561e9b098940 executing computations on platform Host. Devices:\n",
            "2021-04-13 15:56:06.462251: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkzld8_Gty_o"
      },
      "source": [
        "text = r'''\n",
        "import numpy as np\n",
        "from cpd_auto import cpd_auto\n",
        "import h5py\n",
        "\n",
        "DATASET_PATH = \"../vsumm-reinforce/datasets/eccv16_dataset_pokari_google_pool5.h5\"\n",
        "SAMP_RATE = 15  # sampling rate (fps)\n",
        "N_CHANGE_POINTS = 30  # the number of change points\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = h5py.File(DATASET_PATH, \"r+\")\n",
        "\n",
        "    for video_name in dataset.keys():\n",
        "        X = dataset[video_name][\"features_origin\"][...]\n",
        "        n = X.shape[0]\n",
        "        K = np.dot(X, X.T)\n",
        "        cps, scores = cpd_auto(K, N_CHANGE_POINTS, 1)\n",
        "        print(\"Estimated: (m=%d)\" % len(cps), cps)\n",
        "\n",
        "        cps = np.concatenate(([0], cps))\n",
        "        cps = np.concatenate((cps, [n]))\n",
        "\n",
        "        # Update dataset\n",
        "        features = np.array([frame for i, frame in enumerate(X) if i % SAMP_RATE == 0], dtype=np.float64)\n",
        "        change_points = np.array([[cps[i], cps[i + 1] - 1] for i in range(cps.shape[0] - 1)], dtype=np.int64)\n",
        "        n_frames = np.array(n, dtype=np.int64)\n",
        "        n_frame_per_seg = np.array([(p[1] - p[0] + 1) for p in change_points], dtype=np.int64)\n",
        "        picks = np.array([(i * SAMP_RATE) for i in range((n - 1) // SAMP_RATE + 1)], dtype=np.int64)\n",
        "\n",
        "        key = dataset[video_name]\n",
        "        dataset.create_dataset(key + \"/features\", data=features)\n",
        "        dataset.create_dataset(key + \"/change_points\", data=change_points)\n",
        "        dataset.create_dataset(key + \"/n_frames\", data=n_frames)\n",
        "        dataset.create_dataset(key + \"/n_frame_per_seg\", data=n_frame_per_seg)\n",
        "        dataset.create_dataset(key + \"/picks\", data=picks)\n",
        "\n",
        "    dataset.close()\n",
        "'''\n",
        "with open('/content/kts_ver1.1/segment.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFmP9dh38LM"
      },
      "source": [
        "text = r'''\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def calc_scatters(K):\n",
        "    \"\"\"Calculate scatter matrix: scatters[i,j] = {scatter of the sequence with\n",
        "    starting frame i and ending frame j}\n",
        "    \"\"\"\n",
        "    n = K.shape[0]\n",
        "    K1 = np.cumsum([0] + list(np.diag(K)))\n",
        "    K2 = np.zeros((n + 1, n + 1))\n",
        "    # TODO: use the fact that K - symmetric\n",
        "    K2[1:, 1:] = np.cumsum(np.cumsum(K, 0), 1)\n",
        "\n",
        "    diagK2 = np.diag(K2)\n",
        "\n",
        "    i = np.arange(n).reshape((-1, 1))\n",
        "    j = np.arange(n).reshape((1, -1))\n",
        "    scatters = (\n",
        "            K1[1:].reshape((1, -1)) - K1[:-1].reshape((-1, 1)) -\n",
        "            (diagK2[1:].reshape((1, -1)) + diagK2[:-1].reshape((-1, 1)) -\n",
        "             K2[1:, :-1].T - K2[:-1, 1:]) /\n",
        "            ((j - i + 1).astype(np.float32) + (j == i - 1).astype(np.float32))\n",
        "    )\n",
        "    scatters[j < i] = 0\n",
        "\n",
        "    return scatters\n",
        "\n",
        "\n",
        "def cpd_nonlin(K, ncp, lmin=1, lmax=100000, backtrack=True, verbose=True,\n",
        "               out_scatters=None):\n",
        "    \"\"\"Change point detection with dynamic programming\n",
        "    :param K: Square kernel matrix\n",
        "    :param ncp: Number of change points to detect (ncp >= 0)\n",
        "    :param lmin: Minimal length of a segment\n",
        "    :param lmax: Maximal length of a segment\n",
        "    :param backtrack: If False - only evaluate objective scores (to save memory)\n",
        "    :param verbose: If true, print verbose message\n",
        "    :param out_scatters: Output scatters\n",
        "    :return: Tuple (cps, obj_vals)\n",
        "        - cps - detected array of change points: mean is thought to be constant\n",
        "            on [ cps[i], cps[i+1] )\n",
        "        - obj_vals - values of the objective function for 0..m changepoints\n",
        "    \"\"\"\n",
        "    m = int(ncp)  # prevent numpy.int64\n",
        "\n",
        "    n, n1 = K.shape\n",
        "    assert n == n1, 'Kernel matrix awaited.'\n",
        "    assert (m + 1) * lmin <= n <= (m + 1) * lmax\n",
        "    assert 1 <= lmin <= lmax\n",
        "\n",
        "    if verbose:\n",
        "        print('Precomputing scatters...')\n",
        "    J = calc_scatters(K)\n",
        "\n",
        "    if out_scatters is not None:\n",
        "        out_scatters[0] = J\n",
        "\n",
        "    if verbose:\n",
        "        print('Inferring best change points...')\n",
        "    # I[k, l] - value of the objective for k change-points and l first frames\n",
        "    I = 1e101 * np.ones((m + 1, n + 1))\n",
        "    I[0, lmin:lmax] = J[0, lmin - 1:lmax - 1]\n",
        "\n",
        "    if backtrack:\n",
        "        # p[k, l] --- 'previous change' --- best t[k] when t[k+1] equals l\n",
        "        p = np.zeros((m + 1, n + 1), dtype=int)\n",
        "    else:\n",
        "        p = np.zeros((1, 1), dtype=int)\n",
        "\n",
        "    for k in range(1, m + 1):\n",
        "        for l in range((k + 1) * lmin, n + 1):\n",
        "            tmin = max(k * lmin, l - lmax)\n",
        "            tmax = l - lmin + 1\n",
        "            c = J[tmin:tmax, l - 1].reshape(-1) + \\\n",
        "                I[k - 1, tmin:tmax].reshape(-1)\n",
        "            I[k, l] = np.min(c)\n",
        "            if backtrack:\n",
        "                p[k, l] = np.argmin(c) + tmin\n",
        "\n",
        "    # Collect change points\n",
        "    cps = np.zeros(m, dtype=int)\n",
        "\n",
        "    if backtrack:\n",
        "        cur = n\n",
        "        for k in range(m, 0, -1):\n",
        "            cps[k - 1] = p[k, cur]\n",
        "            cur = cps[k - 1]\n",
        "\n",
        "    scores = I[:, n].copy()\n",
        "    scores[scores > 1e99] = np.inf\n",
        "    return cps, scores\n",
        "'''\n",
        "with open('/content/kts_ver1.1/cpd_nonlin.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e7WCFrL1-gG",
        "outputId": "ffbb7b93-ccb0-4d36-95cc-017e5bb86509"
      },
      "source": [
        "%cd /content/kts_ver1.1\n",
        "# python2との違いでエラーになってるっぽい。\n",
        "# もしかしたらh5ファイルを読み込むところから書き換えが必要？\n",
        "!python segment.py"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/kts_ver1.1\n",
            "Precomputing scatters...\n",
            "Inferring best change points...\n",
            "Precomputing scatters...\n",
            "Inferring best change points...\n",
            "Estimated: (m=30) [ 43  70 100 144 158 168 179 186 217 237 270 294 302 332 362 409 451 506\n",
            " 514 548 562 585 612 633 662 683 704 730 751 778]\n",
            "****************************************\n",
            "frames\n",
            "<HDF5 group \"/frames\" (1 members)>\n",
            "<class 'h5py._hl.group.Group'>\n",
            "<KeysViewHDF5 ['features_origin']>\n",
            "['_MutableMapping__marker', '__abstractmethods__', '__bool__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_d', '_e', '_gcpl_crt_order', '_id', '_ipython_key_completions_', '_lapl', '_lcpl', 'attrs', 'clear', 'copy', 'create_dataset', 'create_dataset_like', 'create_group', 'create_virtual_dataset', 'file', 'get', 'id', 'items', 'keys', 'move', 'name', 'parent', 'pop', 'popitem', 'ref', 'regionref', 'require_dataset', 'require_group', 'setdefault', 'update', 'values', 'visit', 'visititems']\n",
            "<bound method MappingHDF5.values of <HDF5 group \"/frames\" (1 members)>>\n",
            "****************************************\n",
            "Traceback (most recent call last):\n",
            "  File \"segment.py\", line 39, in <module>\n",
            "    dataset.create_dataset(key + \"/features\", data=features)\n",
            "TypeError: unsupported operand type(s) for +: 'Group' and 'str'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1avql8mO2zQR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hashibiro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM0nwb94KezOhjJA4uRBe7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsato-code/colab_notebooks/blob/main/hashibiro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHuu8_imiiJr",
        "outputId": "8fe5e623-5360-4534-de50-e2f44fa08375"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 15 15:05:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAbBtNfSim_3",
        "outputId": "747a628d-a993-42b3-bb70-c5dac27dedb4"
      },
      "source": [
        "# 関連リポジトリをクローン\n",
        "%cd /content\n",
        "!git clone https://github.com/KaiyangZhou/vsumm-reinforce"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'vsumm-reinforce'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121\u001b[K\n",
            "Receiving objects: 100% (121/121), 641.05 KiB | 10.17 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7hWFe4ojDuQ",
        "outputId": "d8975855-0aa0-41e6-d9e6-8c41a118ca85"
      },
      "source": [
        "# データセットと学習済みモデルをダウンロード\n",
        "%cd vsumm-reinforce\n",
        "#!wget http://www.eecs.qmul.ac.uk/~kz303/vsumm-reinforce/datasets.tar.gz\n",
        "#!tar -xvzf datasets.tar.gz\n",
        "#!wget http://www.eecs.qmul.ac.uk/~kz303/vsumm-reinforce/models.tar.gz\n",
        "#!tar -xvzf models.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vsumm-reinforce\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BZmwIQIjIrx",
        "outputId": "45b76b20-d3d3-4f36-8f8a-e7e9331daa5c"
      },
      "source": [
        "%cd ..\n",
        "# GoogLeNet for Image Classification\n",
        "!git clone https://github.com/conan7882/GoogLeNet-Inception-tf\n",
        "%cd GoogLeNet-Inception-tf\n",
        "!wget https://www.dropbox.com/sh/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy\n",
        "%cd ..\n",
        "# Kernel Temporal Segmentation\n",
        "!wget http://pascal.inrialpes.fr/data2/potapov/med_summaries/kts_ver1.1.tar.gz\n",
        "!tar -zxvf kts_ver1.1.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'GoogLeNet-Inception-tf'...\n",
            "remote: Enumerating objects: 332, done.\u001b[K\n",
            "remote: Total 332 (delta 0), reused 0 (delta 0), pack-reused 332\u001b[K\n",
            "Receiving objects: 100% (332/332), 11.78 MiB | 44.19 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "/content/GoogLeNet-Inception-tf\n",
            "--2021-04-15 15:06:10--  https://www.dropbox.com/sh/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy [following]\n",
            "--2021-04-15 15:06:10--  https://www.dropbox.com/sh/raw/axnbpd1oe92aoyd/AADJaXakFvqOH8sXkdu6guHta/googlenet.npy\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com/cd/0/inline/BMrDHhC4Yf27tE4cJqT4zkL-2LGO6Ny-Dj6CNjZG_v6zJvcDLVH3c6lhXcAKozmrps8R1q7knhz87KBZzqaGitVwalffXuTyFotHdDH2DaiyjW_BprKl5ieB3lgZAww_oz48ICMPmXm_ji8s4waNpCGp/file# [following]\n",
            "--2021-04-15 15:06:10--  https://uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com/cd/0/inline/BMrDHhC4Yf27tE4cJqT4zkL-2LGO6Ny-Dj6CNjZG_v6zJvcDLVH3c6lhXcAKozmrps8R1q7knhz87KBZzqaGitVwalffXuTyFotHdDH2DaiyjW_BprKl5ieB3lgZAww_oz48ICMPmXm_ji8s4waNpCGp/file\n",
            "Resolving uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com (uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com (uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BMreAHDVSvIchUFaiMew_EmdhpzRnkByuKTHwXTrm2x45WZ1g7UfpAhPBlVaGit9jy2EIgp6ehrv_FS2c9M9fIL7ifp2M8xsVLBkYqlAPLS_Ox6dR8_bZTyyitxhPa9XbiRDNUJFRetWR36tydUjY_VmNzXEsEv1bN701otftSzcfon84XJaYmoOD0Wgco6IEHDZBNpY4-o5w7vZwXza5Jb3ulFdNjSjDBZ82MxS0yLAAcm6NtB2ULZiK4uYUJjvGnIXbS2N9G6HDgFNQs66Mq9l_1XOG08uuyOTVKrdMYEXcJK6z51DsX2VN_Ktjod5ORubcavWtmmj3q7rCqD94wvhz2POioqvvoEhvDoIZgOiLFFrGCV1Rhcmj1Q-yqf45Vo/file [following]\n",
            "--2021-04-15 15:06:11--  https://uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com/cd/0/inline2/BMreAHDVSvIchUFaiMew_EmdhpzRnkByuKTHwXTrm2x45WZ1g7UfpAhPBlVaGit9jy2EIgp6ehrv_FS2c9M9fIL7ifp2M8xsVLBkYqlAPLS_Ox6dR8_bZTyyitxhPa9XbiRDNUJFRetWR36tydUjY_VmNzXEsEv1bN701otftSzcfon84XJaYmoOD0Wgco6IEHDZBNpY4-o5w7vZwXza5Jb3ulFdNjSjDBZ82MxS0yLAAcm6NtB2ULZiK4uYUJjvGnIXbS2N9G6HDgFNQs66Mq9l_1XOG08uuyOTVKrdMYEXcJK6z51DsX2VN_Ktjod5ORubcavWtmmj3q7rCqD94wvhz2POioqvvoEhvDoIZgOiLFFrGCV1Rhcmj1Q-yqf45Vo/file\n",
            "Reusing existing connection to uc21529d8ad5cb9d295fc286d41b.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28000395 (27M) [application/octet-stream]\n",
            "Saving to: ‘googlenet.npy’\n",
            "\n",
            "googlenet.npy       100%[===================>]  26.70M  40.8MB/s    in 0.7s    \n",
            "\n",
            "2021-04-15 15:06:13 (40.8 MB/s) - ‘googlenet.npy’ saved [28000395/28000395]\n",
            "\n",
            "/content\n",
            "--2021-04-15 15:06:13--  http://pascal.inrialpes.fr/data2/potapov/med_summaries/kts_ver1.1.tar.gz\n",
            "Resolving pascal.inrialpes.fr (pascal.inrialpes.fr)... 194.199.16.17\n",
            "Connecting to pascal.inrialpes.fr (pascal.inrialpes.fr)|194.199.16.17|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3431 (3.4K) [application/x-gzip]\n",
            "Saving to: ‘kts_ver1.1.tar.gz’\n",
            "\n",
            "kts_ver1.1.tar.gz   100%[===================>]   3.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-15 15:06:13 (430 MB/s) - ‘kts_ver1.1.tar.gz’ saved [3431/3431]\n",
            "\n",
            "kts_ver1.1/\n",
            "kts_ver1.1/cpd_auto.py\n",
            "kts_ver1.1/cpd_nonlin.py\n",
            "kts_ver1.1/demo.py\n",
            "kts_ver1.1/README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2hHlZ72lLGH",
        "outputId": "f31a8e2e-1b93-4a74-c8e0-c021dca8c309"
      },
      "source": [
        "!mkdir -p data/original\n",
        "%cd data/original"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/original\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MknzUdBlpE6",
        "outputId": "3d994270-94cd-4523-f43a-2c033e32aae3"
      },
      "source": [
        "!pip install pytube\n",
        "from pytube import YouTube\n",
        "import os\n",
        "\n",
        "data_dir = '/content/data/original/'\n",
        "# hot pepper beauty\n",
        "out = YouTube(\"https://www.youtube.com/watch?v=rwt3oS_mFVQ\").streams.first().download()\n",
        "os.rename(out, 'test01.mp4')\n",
        "# GREEN DAKARA\n",
        "out = YouTube(\"https://www.youtube.com/watch?v=cShbQ2pQs94\").streams.first().download()\n",
        "os.rename(out, 'test02.mp4')\n",
        "# ポカリスウェット\n",
        "out = YouTube(\"https://www.youtube.com/watch?v=cKM2HQLK8Pg\").streams.first().download()\n",
        "os.rename(out, 'test03.mp4')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.7/dist-packages (10.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCySbbTv-6Hb"
      },
      "source": [
        "# スクリプトを修正\n",
        "text = r'''\n",
        "#!/bin/bash\n",
        "\n",
        "\"\"\"\n",
        "This script decompose a video into frames\n",
        "How to use: replace path_to_videos and path_to_frames with real paths\n",
        "\"\"\"\n",
        "\n",
        "for f in /content/data/original/*.mp4\n",
        "do\n",
        "  echo \"Processing $f file...\"\n",
        "  # take action on each file. $f store current file name\\\n",
        "  basename=$(ff=${f%.ext} ; echo ${ff##*/})\n",
        "  name=$(echo $basename | cut -d'.' --complement -f2-)\n",
        "  echo $f\n",
        " mkdir -p /content/data/frames/\"$name\"\n",
        " ffmpeg -i \"$f\" -f image2 -qscale:v 2 /content/data/frames/\"$name\"/%06d.jpg\n",
        "done\n",
        "'''\n",
        "with open('/content/vsumm-reinforce/extra-tools/videos2frames.sh', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noCCp8eEnjv5",
        "outputId": "5e24c2ac-74b1-4a11-fa92-ed8006ff3fb4"
      },
      "source": [
        "# 修正したスクリプトを実行\n",
        "%cd /content/vsumm-reinforce/extra-tools\n",
        "!./videos2frames.sh"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vsumm-reinforce/extra-tools\n",
            "./videos2frames.sh: line 7: $'\\nThis script decompose a video into frames\\nHow to use: replace path_to_videos and path_to_frames with real paths\\n': command not found\n",
            "Processing /content/data/original/test01.mp4 file...\n",
            "/content/data/original/test01.mp4\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/data/original/test01.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "  Duration: 00:00:30.09, start: 0.000000, bitrate: 405 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 306 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/18/2021.\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/18/2021.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x563c41896000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/data/frames/test01/%06d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn, 23.98 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-03-18T09:47:36.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/18/2021.\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  720 fps=623 q=2.0 Lsize=N/A time=00:00:30.03 bitrate=N/A speed=  26x    \n",
            "video:20923kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Processing /content/data/original/test02.mp4 file...\n",
            "/content/data/original/test02.mp4\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/data/original/test02.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Google\n",
            "  Duration: 00:00:35.39, start: 0.000000, bitrate: 524 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 426 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x563071ba8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/data/frames/test02/%06d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn, 23.98 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  847 fps=637 q=2.0 Lsize=N/A time=00:00:35.32 bitrate=N/A speed=26.6x    \n",
            "video:25646kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Processing /content/data/original/test03.mp4 file...\n",
            "/content/data/original/test03.mp4\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/data/original/test03.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "  Duration: 00:00:30.09, start: 0.000000, bitrate: 656 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 558 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/06/2021.\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/06/2021.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x5626b65a6000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, image2, to '/content/data/frames/test03/%06d.jpg':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn, 29.97 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-04-07T03:07:52.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 04/06/2021.\n",
            "      encoder         : Lavc57.107.100 mjpeg\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
            "frame=  900 fps=641 q=2.0 Lsize=N/A time=00:00:30.03 bitrate=N/A speed=21.4x    \n",
            "video:21332kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbSxQroNo6b2",
        "outputId": "0d664fc5-56c9-47ac-84e8-0ed886e405b0"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.12.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUz4l8sT_grg"
      },
      "source": [
        "# 特徴量抽出のコード\n",
        "text = r'''\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# File: inception_pretrained.py\n",
        "# Author: Qian Ge <geqian1001@gmail.com>\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "sys.path.append('../')\n",
        "import loader as loader\n",
        "from src.nets.googlenet import GoogLeNet\n",
        "import h5py\n",
        "import src.models.layers as L\n",
        "\n",
        "# PRETRINED_PATH = '/home/qge2/workspace/data/pretrain/inception/googlenet.npy'\n",
        "# DATA_PATH = '../data/'\n",
        "PRETRINED_PATH = '/content/GoogLeNet-Inception-tf/googlenet.npy'\n",
        "DATA_PATH = '/content/data/frames/test01/'\n",
        "DATASET_PATH = '/content/vsumm-reinforce/datasets/eccv16_dataset_pokari_google_pool5.h5'\n",
        "IM_CHANNEL = 3\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--pretrained_path', type=str, default=PRETRINED_PATH,\n",
        "                        help='Directory of pretrain model')\n",
        "    parser.add_argument('--im_name', type=str, default='.jpg',\n",
        "                        help='Part of image name')\n",
        "    parser.add_argument('--data_path', type=str, default=DATA_PATH,\n",
        "                        help='Directory of test images')\n",
        "    \n",
        "    return parser.parse_args()\n",
        "\n",
        "def test_pre_trained():\n",
        "    FLAGS = get_args()\n",
        "    # Read ImageNet label into a dictionary\n",
        "    label_dict = loader.load_label_dict()\n",
        "    # Create a Dataflow object for test images\n",
        "    image_data = loader.read_image(\n",
        "        im_name=FLAGS.im_name, n_channel=IM_CHANNEL,\n",
        "        data_dir=FLAGS.data_path, batch_size=1)\n",
        "\n",
        "    # Create a testing GoogLeNet model\n",
        "    test_model = GoogLeNet(\n",
        "        n_channel=IM_CHANNEL, n_class=1000, pre_trained_path=FLAGS.pretrained_path)\n",
        "    test_model.create_test_model()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        dataset = h5py.File(DATASET_PATH, 'w')\n",
        "        video_name = FLAGS.data_path.split('/')[-2]\n",
        "        features = np.empty((1, 1024), dtype=np.float64)  # Put dummy\n",
        "\n",
        "        while image_data.epochs_completed < 1:\n",
        "            # read batch files\n",
        "            batch_data = image_data.next_batch_dict()\n",
        "            # get batch file names\n",
        "            batch_file_name = image_data.get_batch_file_name()[0]\n",
        "            # get prediction results\n",
        "            #pred = sess.run(test_model.layers['top_5'],\n",
        "            feature = sess.run(L.global_avg_pool(test_model.layers['inception_out']),\n",
        "                            feed_dict={test_model.image: batch_data['image']})\n",
        "            features = np.concatenate((features, feature))\n",
        "\n",
        "        dataset.create_dataset('{}/features_origin'.format(video_name), data=features[1:])\n",
        "        dataset.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_pre_trained()\n",
        "'''\n",
        "with open('/content/GoogLeNet-Inception-tf/examples/feature_extraction.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2gygOL2sNyO",
        "outputId": "51165bbb-623c-4dd4-d575-d1b85357a9dd"
      },
      "source": [
        "%cd /content/GoogLeNet-Inception-tf/examples\n",
        "\n",
        "# これは一時的に必要なディレクトリ\n",
        "!mkdir -p /content/vsumm-reinforce/datasets\n",
        "# ディレクトリのパス設定次第でok\n",
        "!python feature_extraction.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GoogLeNet-Inception-tf/examples\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Load conv1_7x7_s2 weights!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Load conv1_7x7_s2 biases!\n",
            "Load conv2_3x3_reduce weights!\n",
            "Load conv2_3x3_reduce biases!\n",
            "Load conv2_3x3 weights!\n",
            "Load conv2_3x3 biases!\n",
            "Load inception_3a_1x1 weights!\n",
            "Load inception_3a_1x1 biases!\n",
            "Load inception_3a_3x3_reduce weights!\n",
            "Load inception_3a_3x3_reduce biases!\n",
            "Load inception_3a_3x3 weights!\n",
            "Load inception_3a_3x3 biases!\n",
            "Load inception_3a_5x5_reduce weights!\n",
            "Load inception_3a_5x5_reduce biases!\n",
            "Load inception_3a_5x5 weights!\n",
            "Load inception_3a_5x5 biases!\n",
            "Load inception_3a_pool_proj weights!\n",
            "Load inception_3a_pool_proj biases!\n",
            "Load inception_3b_1x1 weights!\n",
            "Load inception_3b_1x1 biases!\n",
            "Load inception_3b_3x3_reduce weights!\n",
            "Load inception_3b_3x3_reduce biases!\n",
            "Load inception_3b_3x3 weights!\n",
            "Load inception_3b_3x3 biases!\n",
            "Load inception_3b_5x5_reduce weights!\n",
            "Load inception_3b_5x5_reduce biases!\n",
            "Load inception_3b_5x5 weights!\n",
            "Load inception_3b_5x5 biases!\n",
            "Load inception_3b_pool_proj weights!\n",
            "Load inception_3b_pool_proj biases!\n",
            "Load inception_4a_1x1 weights!\n",
            "Load inception_4a_1x1 biases!\n",
            "Load inception_4a_3x3_reduce weights!\n",
            "Load inception_4a_3x3_reduce biases!\n",
            "Load inception_4a_3x3 weights!\n",
            "Load inception_4a_3x3 biases!\n",
            "Load inception_4a_5x5_reduce weights!\n",
            "Load inception_4a_5x5_reduce biases!\n",
            "Load inception_4a_5x5 weights!\n",
            "Load inception_4a_5x5 biases!\n",
            "Load inception_4a_pool_proj weights!\n",
            "Load inception_4a_pool_proj biases!\n",
            "Load inception_4b_1x1 weights!\n",
            "Load inception_4b_1x1 biases!\n",
            "Load inception_4b_3x3_reduce weights!\n",
            "Load inception_4b_3x3_reduce biases!\n",
            "Load inception_4b_3x3 weights!\n",
            "Load inception_4b_3x3 biases!\n",
            "Load inception_4b_5x5_reduce weights!\n",
            "Load inception_4b_5x5_reduce biases!\n",
            "Load inception_4b_5x5 weights!\n",
            "Load inception_4b_5x5 biases!\n",
            "Load inception_4b_pool_proj weights!\n",
            "Load inception_4b_pool_proj biases!\n",
            "Load inception_4c_1x1 weights!\n",
            "Load inception_4c_1x1 biases!\n",
            "Load inception_4c_3x3_reduce weights!\n",
            "Load inception_4c_3x3_reduce biases!\n",
            "Load inception_4c_3x3 weights!\n",
            "Load inception_4c_3x3 biases!\n",
            "Load inception_4c_5x5_reduce weights!\n",
            "Load inception_4c_5x5_reduce biases!\n",
            "Load inception_4c_5x5 weights!\n",
            "Load inception_4c_5x5 biases!\n",
            "Load inception_4c_pool_proj weights!\n",
            "Load inception_4c_pool_proj biases!\n",
            "Load inception_4d_1x1 weights!\n",
            "Load inception_4d_1x1 biases!\n",
            "Load inception_4d_3x3_reduce weights!\n",
            "Load inception_4d_3x3_reduce biases!\n",
            "Load inception_4d_3x3 weights!\n",
            "Load inception_4d_3x3 biases!\n",
            "Load inception_4d_5x5_reduce weights!\n",
            "Load inception_4d_5x5_reduce biases!\n",
            "Load inception_4d_5x5 weights!\n",
            "Load inception_4d_5x5 biases!\n",
            "Load inception_4d_pool_proj weights!\n",
            "Load inception_4d_pool_proj biases!\n",
            "Load inception_4e_1x1 weights!\n",
            "Load inception_4e_1x1 biases!\n",
            "Load inception_4e_3x3_reduce weights!\n",
            "Load inception_4e_3x3_reduce biases!\n",
            "Load inception_4e_3x3 weights!\n",
            "Load inception_4e_3x3 biases!\n",
            "Load inception_4e_5x5_reduce weights!\n",
            "Load inception_4e_5x5_reduce biases!\n",
            "Load inception_4e_5x5 weights!\n",
            "Load inception_4e_5x5 biases!\n",
            "Load inception_4e_pool_proj weights!\n",
            "Load inception_4e_pool_proj biases!\n",
            "Load inception_5a_1x1 weights!\n",
            "Load inception_5a_1x1 biases!\n",
            "Load inception_5a_3x3_reduce weights!\n",
            "Load inception_5a_3x3_reduce biases!\n",
            "Load inception_5a_3x3 weights!\n",
            "Load inception_5a_3x3 biases!\n",
            "Load inception_5a_5x5_reduce weights!\n",
            "Load inception_5a_5x5_reduce biases!\n",
            "Load inception_5a_5x5 weights!\n",
            "Load inception_5a_5x5 biases!\n",
            "Load inception_5a_pool_proj weights!\n",
            "Load inception_5a_pool_proj biases!\n",
            "Load inception_5b_1x1 weights!\n",
            "Load inception_5b_1x1 biases!\n",
            "Load inception_5b_3x3_reduce weights!\n",
            "Load inception_5b_3x3_reduce biases!\n",
            "Load inception_5b_3x3 weights!\n",
            "Load inception_5b_3x3 biases!\n",
            "Load inception_5b_5x5_reduce weights!\n",
            "Load inception_5b_5x5_reduce biases!\n",
            "Load inception_5b_5x5 weights!\n",
            "Load inception_5b_5x5 biases!\n",
            "Load inception_5b_pool_proj weights!\n",
            "Load inception_5b_pool_proj biases!\n",
            "Load loss3_classifier weights!\n",
            "Load loss3_classifier biases!\n",
            "2021-04-15 15:24:15.598936: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-15 15:24:15.602404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-04-15 15:24:15.602841: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5646b121e940 executing computations on platform Host. Devices:\n",
            "2021-04-15 15:24:15.602894: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "********************************************************************************\n",
            "test01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkzld8_Gty_o"
      },
      "source": [
        "text = r'''\n",
        "import numpy as np\n",
        "from cpd_auto import cpd_auto\n",
        "import h5py\n",
        "\n",
        "DATASET_PATH = \"../vsumm-reinforce/datasets/eccv16_dataset_pokari_google_pool5.h5\"\n",
        "SAMP_RATE = 15  # sampling rate (fps)\n",
        "N_CHANGE_POINTS = 30  # the number of change points\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = h5py.File(DATASET_PATH, \"r+\")\n",
        "\n",
        "    for video_name in dataset.keys():\n",
        "        X = dataset[video_name][\"features_origin\"][...]\n",
        "        n = X.shape[0]\n",
        "        K = np.dot(X, X.T)\n",
        "        cps, scores = cpd_auto(K, N_CHANGE_POINTS, 1)\n",
        "        print(\"Estimated: (m=%d)\" % len(cps), cps)\n",
        "\n",
        "        cps = np.concatenate(([0], cps))\n",
        "        cps = np.concatenate((cps, [n]))\n",
        "\n",
        "        # Update dataset\n",
        "        features = np.array([frame for i, frame in enumerate(X) if i % SAMP_RATE == 0], dtype=np.float64)\n",
        "        change_points = np.array([[cps[i], cps[i + 1] - 1] for i in range(cps.shape[0] - 1)], dtype=np.int64)\n",
        "        n_frames = np.array(n, dtype=np.int64)\n",
        "        n_frame_per_seg = np.array([(p[1] - p[0] + 1) for p in change_points], dtype=np.int64)\n",
        "        picks = np.array([(i * SAMP_RATE) for i in range((n - 1) // SAMP_RATE + 1)], dtype=np.int64)\n",
        "\n",
        "        key = dataset[video_name]\n",
        "        dataset.create_dataset(key + \"/features\", data=features)\n",
        "        dataset.create_dataset(key + \"/change_points\", data=change_points)\n",
        "        dataset.create_dataset(key + \"/n_frames\", data=n_frames)\n",
        "        dataset.create_dataset(key + \"/n_frame_per_seg\", data=n_frame_per_seg)\n",
        "        dataset.create_dataset(key + \"/picks\", data=picks)\n",
        "\n",
        "    dataset.close()\n",
        "'''\n",
        "with open('/content/kts_ver1.1/segment.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFmP9dh38LM"
      },
      "source": [
        "text = r'''\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def calc_scatters(K):\n",
        "    \"\"\"Calculate scatter matrix: scatters[i,j] = {scatter of the sequence with\n",
        "    starting frame i and ending frame j}\n",
        "    \"\"\"\n",
        "    n = K.shape[0]\n",
        "    K1 = np.cumsum([0] + list(np.diag(K)))\n",
        "    K2 = np.zeros((n + 1, n + 1))\n",
        "    # TODO: use the fact that K - symmetric\n",
        "    K2[1:, 1:] = np.cumsum(np.cumsum(K, 0), 1)\n",
        "\n",
        "    diagK2 = np.diag(K2)\n",
        "\n",
        "    i = np.arange(n).reshape((-1, 1))\n",
        "    j = np.arange(n).reshape((1, -1))\n",
        "    scatters = (\n",
        "            K1[1:].reshape((1, -1)) - K1[:-1].reshape((-1, 1)) -\n",
        "            (diagK2[1:].reshape((1, -1)) + diagK2[:-1].reshape((-1, 1)) -\n",
        "             K2[1:, :-1].T - K2[:-1, 1:]) /\n",
        "            ((j - i + 1).astype(np.float32) + (j == i - 1).astype(np.float32))\n",
        "    )\n",
        "    scatters[j < i] = 0\n",
        "\n",
        "    return scatters\n",
        "\n",
        "\n",
        "def cpd_nonlin(K, ncp, lmin=1, lmax=100000, backtrack=True, verbose=True,\n",
        "               out_scatters=None):\n",
        "    \"\"\"Change point detection with dynamic programming\n",
        "    :param K: Square kernel matrix\n",
        "    :param ncp: Number of change points to detect (ncp >= 0)\n",
        "    :param lmin: Minimal length of a segment\n",
        "    :param lmax: Maximal length of a segment\n",
        "    :param backtrack: If False - only evaluate objective scores (to save memory)\n",
        "    :param verbose: If true, print verbose message\n",
        "    :param out_scatters: Output scatters\n",
        "    :return: Tuple (cps, obj_vals)\n",
        "        - cps - detected array of change points: mean is thought to be constant\n",
        "            on [ cps[i], cps[i+1] )\n",
        "        - obj_vals - values of the objective function for 0..m changepoints\n",
        "    \"\"\"\n",
        "    m = int(ncp)  # prevent numpy.int64\n",
        "\n",
        "    n, n1 = K.shape\n",
        "    assert n == n1, 'Kernel matrix awaited.'\n",
        "    assert (m + 1) * lmin <= n <= (m + 1) * lmax\n",
        "    assert 1 <= lmin <= lmax\n",
        "\n",
        "    if verbose:\n",
        "        print('Precomputing scatters...')\n",
        "    J = calc_scatters(K)\n",
        "\n",
        "    if out_scatters is not None:\n",
        "        out_scatters[0] = J\n",
        "\n",
        "    if verbose:\n",
        "        print('Inferring best change points...')\n",
        "    # I[k, l] - value of the objective for k change-points and l first frames\n",
        "    I = 1e101 * np.ones((m + 1, n + 1))\n",
        "    I[0, lmin:lmax] = J[0, lmin - 1:lmax - 1]\n",
        "\n",
        "    if backtrack:\n",
        "        # p[k, l] --- 'previous change' --- best t[k] when t[k+1] equals l\n",
        "        p = np.zeros((m + 1, n + 1), dtype=int)\n",
        "    else:\n",
        "        p = np.zeros((1, 1), dtype=int)\n",
        "\n",
        "    for k in range(1, m + 1):\n",
        "        for l in range((k + 1) * lmin, n + 1):\n",
        "            tmin = max(k * lmin, l - lmax)\n",
        "            tmax = l - lmin + 1\n",
        "            c = J[tmin:tmax, l - 1].reshape(-1) + \\\n",
        "                I[k - 1, tmin:tmax].reshape(-1)\n",
        "            I[k, l] = np.min(c)\n",
        "            if backtrack:\n",
        "                p[k, l] = np.argmin(c) + tmin\n",
        "\n",
        "    # Collect change points\n",
        "    cps = np.zeros(m, dtype=int)\n",
        "\n",
        "    if backtrack:\n",
        "        cur = n\n",
        "        for k in range(m, 0, -1):\n",
        "            cps[k - 1] = p[k, cur]\n",
        "            cur = cps[k - 1]\n",
        "\n",
        "    scores = I[:, n].copy()\n",
        "    scores[scores > 1e99] = np.inf\n",
        "    return cps, scores\n",
        "'''\n",
        "with open('/content/kts_ver1.1/cpd_nonlin.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e7WCFrL1-gG",
        "outputId": "60c2bc7f-d51f-41ed-a827-d3bd59cd7fb9"
      },
      "source": [
        "%cd /content/kts_ver1.1\n",
        "# python2との違いでエラーになってるっぽい。\n",
        "# もしかしたらh5ファイルを読み込むところから書き換えが必要？\n",
        "!python segment.py"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/kts_ver1.1\n",
            "Precomputing scatters...\n",
            "Inferring best change points...\n",
            "Precomputing scatters...\n",
            "Inferring best change points...\n",
            "Estimated: (m=30) [ 30  73  90 108 129 175 202 232 254 268 283 309 347 376 390 434 464 488\n",
            " 504 531 572 660 664 668 673 680 690 698 701 704]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1avql8mO2zQR"
      },
      "source": [
        "text = r'''\n",
        "import theano\n",
        "from theano import tensor as T\n",
        "\n",
        "import theano_nets\n",
        "from model_reinforceRNN import reinforceRNN\n",
        "\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time, math, os, sys, h5py, logging, vsum_tools, argparse\n",
        "import os.path as osp\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "_DTYPE = theano.config.floatX\n",
        "_PROPORTION = 0.10  # proportion to leave as a summary\n",
        "\n",
        "def test(n_episodes=5,\n",
        "         input_dim=1024,\n",
        "         hidden_dim=256,\n",
        "         W_init='normal',\n",
        "         U_init='normal',\n",
        "         weight_decay=1e-5,\n",
        "         regularizer='L2',\n",
        "         optimizer='adam',\n",
        "         alpha=0.01,\n",
        "         model_file='',\n",
        "         eval_dataset='summe',\n",
        "         verbose=True,\n",
        "         ):\n",
        "    # assert eval_dataset in ['summe', 'tvsum']\n",
        "    assert os.path.isfile(model_file)\n",
        "\n",
        "    if eval_dataset == 'summe':\n",
        "        eval_metric = 'max'\n",
        "    elif eval_dataset == 'tvsum':\n",
        "        eval_metric = 'avg'\n",
        "    model_options = locals().copy()\n",
        "\n",
        "    log_dir = 'log-test'\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.mkdir(log_dir)\n",
        "\n",
        "    logging.basicConfig(\n",
        "      filename=log_dir+'/log.txt',\n",
        "      filemode='w',\n",
        "      format='%(asctime)s %(message)s',\n",
        "      datefmt='[%d/%m/%Y %I:%M:%S]',\n",
        "      level=logging.INFO\n",
        "    )\n",
        "\n",
        "    logger = logging.getLogger()\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter(fmt='%(asctime)s %(message)s',datefmt='[%d/%m/%Y %I:%M:%S]')\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "    logger.info('initializing net model')\n",
        "    net = reinforceRNN(model_options)\n",
        "\n",
        "    logger.info('loading %s data' % (eval_dataset))\n",
        "    h5f_path = 'datasets/eccv16_dataset_' + eval_dataset + '_google_pool5.h5'\n",
        "    # dataset = h5py.File(h5f_path, 'r')\n",
        "    dataset = h5py.File(h5f_path, 'r+')\n",
        "    if sys.version_info[0] == 3:\n",
        "        dataset_keys = list(dataset.keys())\n",
        "    else:\n",
        "        dataset_keys = dataset.keys()\n",
        "    n_videos = len(dataset_keys)\n",
        "\n",
        "    logger.info('=> testing')\n",
        "    start_time = time.time()\n",
        "    fms = []\n",
        "    precs = []\n",
        "    recs = []\n",
        "\n",
        "    # save output results to h5 file\n",
        "    # h5_res = h5py.File(osp.join(log_dir, 'result.h5'), 'w')\n",
        "\n",
        "    for i_video in range(n_videos):\n",
        "        key = dataset_keys[i_video]\n",
        "        data_x = dataset[key]['features'][...].astype(_DTYPE)\n",
        "        probs = net.model_inference(data_x)\n",
        "\n",
        "        cps = dataset[key]['change_points'][...]\n",
        "        n_frames = dataset[key]['n_frames'][()]\n",
        "        nfps = dataset[key]['n_frame_per_seg'][...].tolist()\n",
        "        positions = dataset[key]['picks'][...]\n",
        "\n",
        "        # machine_summary = vsum_tools.generate_summary(probs, cps, n_frames, nfps, positions)\n",
        "        machine_summary = vsum_tools.generate_summary(probs, cps, n_frames, nfps, positions, _PROPORTION)\n",
        "        # user_summary = dataset[key]['user_summary'][...]\n",
        "        # fm,prec,rec = vsum_tools.evaluate_summary(machine_summary, user_summary, eval_metric)\n",
        "        # fms.append(fm)\n",
        "        # precs.append(prec)\n",
        "        # recs.append(rec)\n",
        "        # if verbose: logger.info('video %s. fm=%f' % (key, fm))\n",
        "\n",
        "        # save results for each test video\n",
        "        # h5_res.create_dataset(key + '/score', data=probs)\n",
        "        # h5_res.create_dataset(key + '/machine_summary', data=machine_summary)\n",
        "        # h5_res.create_dataset(key + '/gtscore', data=dataset[key]['gtscore'][...])\n",
        "        # h5_res.create_dataset(key + '/fm', data=fm)\n",
        "        dataset.create_dataset(key + '/machine_summary', data=machine_summary)\n",
        "\n",
        "    # h5_res.close()\n",
        "\n",
        "    # mean_fm = np.mean(fms)\n",
        "    # mean_prec = np.mean(precs)\n",
        "    # mean_rec = np.mean(recs)\n",
        "\n",
        "    logger.info('========================= conclusion =========================')\n",
        "    logger.info('-- recap of model options')\n",
        "    logger.info(str(model_options))\n",
        "    # logger.info('-- final outcome')\n",
        "    # logger.info('f-measure {:.1%}. precision {:.1%}. recall {:.1%}.'.format(mean_fm, mean_prec, mean_rec))\n",
        "    elapsed_time = time.time() - start_time\n",
        "    logger.info('elapsed time %.2f s' % (elapsed_time))\n",
        "    logger.info('==============================================================')\n",
        "\n",
        "    dataset.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-model', type=str, default='', metavar='PATH')\n",
        "    parser.add_argument('-d', type=str, default='tvsum')\n",
        "    parser.add_argument('--in-dim', type=int, default=1024,\n",
        "                        help=\"input dimension, i.e. dimension of CNN features\")\n",
        "    parser.add_argument('--h-dim', type=int, default=256,\n",
        "                        help=\"hidden dimension of RNN\")\n",
        "    parser.add_argument('--verbose', action='store_true')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    test(input_dim=args.in_dim,\n",
        "         hidden_dim=args.h_dim,\n",
        "         model_file=args.model,\n",
        "         eval_dataset=args.d,\n",
        "         verbose=args.verbose)\n",
        "'''\n",
        "with open('/content/vsumm-reinforce/vsum_gen.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc20ndLORrd"
      },
      "source": [
        "text = r'''\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "------------------------------------------------\n",
        "Use dynamic programming (DP) to solve 0/1 knapsack problem\n",
        "Time complexity: O(nW), where n is number of items and W is capacity\n",
        "\n",
        "Author: Kaiyang Zhou\n",
        "Website: https://kaiyangzhou.github.io/\n",
        "------------------------------------------------\n",
        "knapsack_dp(values,weights,n_items,capacity,return_all=False)\n",
        "\n",
        "Input arguments:\n",
        "  1. values: a list of numbers in either int or float, specifying the values of items\n",
        "  2. weights: a list of int numbers specifying weights of items\n",
        "  3. n_items: an int number indicating number of items\n",
        "  4. capacity: an int number indicating the knapsack capacity\n",
        "  5. return_all: whether return all info, defaulty is False (optional)\n",
        "\n",
        "Return:\n",
        "  1. picks: a list of numbers storing the positions of selected items\n",
        "  2. max_val: maximum value (optional)\n",
        "------------------------------------------------\n",
        "\"\"\"\n",
        "def knapsack_dp(values,weights,n_items,capacity,return_all=False):\n",
        "    check_inputs(values,weights,n_items,capacity)\n",
        "\n",
        "    table = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
        "    keep = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
        "\n",
        "    for i in xrange(1,n_items+1):\n",
        "        for w in xrange(0,capacity+1):\n",
        "            wi = weights[i-1] # weight of current item\n",
        "            vi = values[i-1] # value of current item\n",
        "            if (wi <= w) and (vi + table[i-1,w-wi] > table[i-1,w]):\n",
        "                table[i,w] = vi + table[i-1,w-wi]\n",
        "                keep[i,w] = 1\n",
        "            else:\n",
        "                table[i,w] = table[i-1,w]\n",
        "\n",
        "    picks = []\n",
        "    K = capacity\n",
        "\n",
        "    for i in xrange(n_items,0,-1):\n",
        "        if keep[i,K] == 1:\n",
        "            picks.append(i)\n",
        "            K -= weights[i-1]\n",
        "\n",
        "    picks.sort()\n",
        "    picks = [x-1 for x in picks] # change to 0-index\n",
        "\n",
        "    if return_all:\n",
        "        max_val = table[n_items,capacity]\n",
        "        return picks,max_val\n",
        "    return picks\n",
        "\n",
        "def check_inputs(values,weights,n_items,capacity):\n",
        "    # check variable type\n",
        "    assert(isinstance(values,list))\n",
        "    assert(isinstance(weights,list))\n",
        "    assert(isinstance(n_items,int))\n",
        "    assert(isinstance(capacity,int))\n",
        "    # check value type\n",
        "    assert(all(isinstance(val,int) or isinstance(val,float) for val in values))\n",
        "    assert(all(isinstance(val,int) for val in weights))\n",
        "    # check validity of value\n",
        "    assert(all(val >= 0 for val in weights))\n",
        "    assert(n_items > 0)\n",
        "    assert(capacity > 0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    values = [2,3,4]\n",
        "    weights = [1,2,3]\n",
        "    n_items = 3\n",
        "    capacity = 3\n",
        "    picks = knapsack_dp(values,weights,n_items,capacity)\n",
        "    print(picks)\n",
        "'''\n",
        "with open('/content/vsumm-reinforce/knapsack.py', 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1iHGaiPPvzB",
        "outputId": "394ca133-f581-4aae-9c7e-9c2c68ba9a53"
      },
      "source": [
        "!pip install gdown\n",
        "!gdown \"https://drive.google.com/uc?export=download&id=1Bf0beMN_ieiM3JpprghaoOwQe9QJIyAN\" \\\n",
        "    -O /content/vsumm-reinforce/datasets/datasets.zip\n",
        "!unzip /content/vsumm-reinforce/datasets/datasets.zip"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1Bf0beMN_ieiM3JpprghaoOwQe9QJIyAN\n",
            "To: /content/vsumm-reinforce/datasets/datasets.zip\n",
            "173MB [00:01, 98.0MB/s]\n",
            "Archive:  /content/vsumm-reinforce/datasets/datasets.zip\n",
            "  inflating: datasets/eccv16_dataset_ovp_google_pool5.h5  \n",
            "  inflating: datasets/eccv16_dataset_tvsum_google_pool5.h5  \n",
            "  inflating: datasets/eccv16_dataset_summe_google_pool5.h5  \n",
            "  inflating: datasets/readme.txt     \n",
            "  inflating: datasets/eccv16_dataset_youtube_google_pool5.h5  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlFptR4xMe0A",
        "outputId": "f6adf4a8-3d6b-4300-df76-7b6088fcd093"
      },
      "source": [
        "# numpyのエラー？\n",
        "# .astype('float32')が必要？？\n",
        "!python vsum_train.py \\\n",
        "    --dataset datasets/eccv16_dataset_tvsum_google_pool5.h5 \\\n",
        "    --max-epochs 60 \\\n",
        "    --hidden-dim 256"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15/04/2021 04:04:26] model options: {'n_episodes': 5, 'input_dim': 1024, 'hidden_dim': 256, 'W_init': 'normal', 'U_init': 'normal', 'weight_decay': 1e-05, 'regularizer': 'L2', 'optimizer': 'adam', 'base_lr': 1e-05, 'decay_rate': 0.1, 'max_epochs': 60, 'decay_stepsize': -1, 'ignore_distant_sim': False, 'distant_sim_thre': 20, 'alpha': 0.01, 'model_file': None, 'disp_freq': 1, 'train_dataset_path': 'datasets/eccv16_dataset_tvsum_google_pool5.h5'}\n",
            "[15/04/2021 04:04:26] initializing net model\n",
            "Traceback (most recent call last):\n",
            "  File \"vsum_train.py\", line 158, in <module>\n",
            "    train_dataset_path=args.dataset)\n",
            "  File \"vsum_train.py\", line 56, in train\n",
            "    net = reinforceRNN(model_options)\n",
            "  File \"/content/vsumm-reinforce/model_reinforceRNN.py\", line 40, in __init__\n",
            "    init_state=None, init_memory=None, go_backwards=False\n",
            "  File \"/content/vsumm-reinforce/theano_nets.py\", line 342, in __init__\n",
            "    self.output = self.step(self.state_below)\n",
            "  File \"/content/vsumm-reinforce/theano_nets.py\", line 396, in step\n",
            "    go_backwards=self.go_backwards\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/theano/scan_module/scan.py\", line 1077, in scan\n",
            "    scan_outs = local_op(*scan_inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/theano/gof/op.py\", line 615, in __call__\n",
            "    node = self.make_node(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/theano/scan_module/scan_op.py\", line 546, in make_node\n",
            "    inner_sitsot_out.type.dtype))\n",
            "ValueError: When compiling the inner function of scan the following error has been encountered: The initial state (`outputs_info` in scan nomenclature) of variable IncSubtensor{Set;:int64:}.0 (argument number 1) has dtype float32, while the result of the inner function (`fn`) has dtype float64. This can happen if the inner function of scan results in an upcast or downcast.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QysIkmT_MYV4",
        "outputId": "30d83315-b25b-48d4-eee3-328bd8d32478"
      },
      "source": [
        "%cd /content/vsumm-reinforce\n",
        "!THEANO_FLAGS='floatX=float32,device=cuda0' \n",
        "!python vsum_gen.py -model models/model_tvsum_reinforceRNN.h5 -d test01"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vsumm-reinforce\n",
            "Traceback (most recent call last):\n",
            "  File \"vsum_gen.py\", line 139, in <module>\n",
            "    verbose=args.verbose)\n",
            "  File \"vsum_gen.py\", line 31, in test\n",
            "    assert os.path.isfile(model_file)\n",
            "AssertionError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biHAKSSlRPyN"
      },
      "source": [
        "# モデルファイルがないし、つくれないぽい\n",
        "# 今のところ、エラー"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}